{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T14:08:24.224514Z",
     "start_time": "2017-07-11T14:08:24.219494Z"
    },
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "The scoring function is the Root Mean Squared Logarithmic Error given by\n",
    "\n",
    "$ \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\log(p_i + 1) - \\log(a_i+1))^2 } $\n",
    "\n",
    "Where\n",
    "\n",
    "* $n$ is the number of hours in the test set\n",
    "* $pi$ is your predicted count\n",
    "* $ai$ is the actual count\n",
    "* $log(x)log‚Å°(x)$ is the natural logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T13:49:00.660883Z",
     "start_time": "2017-07-11T13:49:00.653501Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_):\n",
    "    log1 = numpy.nan_to_num(numpy.array([numpy.log(v + 1) \n",
    "                                         for v \n",
    "                                         in y]))\n",
    "    log2 = numpy.nan_to_num(numpy.array([numpy.log(v + 1) \n",
    "                                         for v \n",
    "                                         in y_]))\n",
    "    calc = (log1 - log2) ** 2\n",
    "    return numpy.sqrt(numpy.mean(calc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "All of the data is already numeric except for datetime. Convert the datetime into distinct numeric parameters for hour, day, month and year. Then display the summary of the data as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T13:46:16.611853Z",
     "start_time": "2017-07-11T13:46:16.493370Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             season       holiday    workingday       weather         temp  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
      "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
      "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
      "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
      "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
      "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
      "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
      "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
      "\n",
      "              atemp      humidity     windspeed        casual    registered  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
      "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
      "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
      "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
      "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
      "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
      "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
      "\n",
      "              count          hour           day         month          year  \n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000  \n",
      "mean     191.574132     11.541613      9.992559      6.521495   2011.501929  \n",
      "std      181.144454      6.915838      5.476608      3.444373      0.500019  \n",
      "min        1.000000      0.000000      1.000000      1.000000   2011.000000  \n",
      "25%       42.000000      6.000000      5.000000      4.000000   2011.000000  \n",
      "50%      145.000000     12.000000     10.000000      7.000000   2012.000000  \n",
      "75%      284.000000     18.000000     15.000000     10.000000   2012.000000  \n",
      "max      977.000000     23.000000     19.000000     12.000000   2012.000000  \n"
     ]
    }
   ],
   "source": [
    "def coerceData(data):\n",
    "    data['hour'] = data.datetime.apply(lambda x: x.split()[1].split(':')[0]).astype('int')\n",
    "    data['day'] = data.datetime.apply(lambda x: x.split()[0].split('-')[2]).astype('int')\n",
    "    data['month'] = data.datetime.apply(lambda x: x.split()[0].split('-')[1]).astype('int')\n",
    "    data['year'] = data.datetime.apply(lambda x: x.split()[0].split('-')[0]).astype('int')\n",
    "    data = data.drop(['datetime'], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = coerceData(pandas.read_csv('train.csv'))\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Data\n",
    "\n",
    "Split out the given training data into a train and a test set and use all of the available parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T13:46:24.673707Z",
     "start_time": "2017-07-11T13:46:24.663253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8164 training examples and 2722 testing examples\n",
      "12 model parameters\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['count', 'casual', 'registered'], axis=1).values\n",
    "y = data['count'].values\n",
    "X_train, X_dev, y_train, y_dev = model_selection.train_test_split(X,\n",
    "                                                                  y,\n",
    "                                                                  random_state=1)\n",
    "\n",
    "print('{0} training examples and {1} testing examples'.format(X_train.shape[0], \n",
    "                                                              X_dev.shape[0]))\n",
    "print('{0} model parameters'.format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Decision Tree ensembles, particularly Boosted Decision Trees, have fairly good performance over a wide variety of use cases as demonstrated [here](https://ucb-mids.s3.amazonaws.com/prod/DATASCI+W207+Intro+to+Machine+Learning/Readings/caruana.icml06.pdf). So we will use GridSearch to tune over a range values of max depth for a Gradient Descent Boosted Decision Tree Regressor. We will also use the given RMSLE error function as a custom scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T14:23:27.390003Z",
     "start_time": "2017-07-11T14:23:27.377337Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositiveIntegerGradientBoostingRegressor(GradientBoostingRegressor):\n",
    "    def predict(self, X):\n",
    "        prediction = super(PositiveIntegerGradientBoostingRegressor, self).predict(X)\n",
    "        return numpy.around(prediction.clip(0))\n",
    "    \n",
    "param_grid = [\n",
    "  {'max_depth': list(range(1,15))}\n",
    " ]\n",
    "\n",
    "regressor = PositiveIntegerGradientBoostingRegressor(n_estimators=100) \n",
    "\n",
    "scorer = metrics.make_scorer(score_func=rmsle, \n",
    "                             greater_is_better=False)\n",
    "model = model_selection.GridSearchCV(regressor, \n",
    "                                     param_grid, \n",
    "                                     scorer,\n",
    "                                     n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fit\n",
    "\n",
    "Fit the model and evaluate the resulting predictions on the held out dev data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T14:24:29.036593Z",
     "start_time": "2017-07-11T14:23:29.504948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 11}\n",
      "RMSLE: 0.09080789737748393\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train)\n",
    "print('Best Parameters: {0}'.format(model.best_params_))\n",
    "print('RMSLE: {0}'.format(rmsle(y_dev, \n",
    "                                model.predict(X_dev))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Submission\n",
    "\n",
    "In order to submit to kaggle we have to generate predictions from the test set and output them to a file with the following format\n",
    "\n",
    "~~~~\n",
    "datetime,count\n",
    "2011-01-20 00:00:00,0\n",
    "2011-01-20 01:00:00,0\n",
    "2011-01-20 02:00:00,0\n",
    "...\n",
    "...\n",
    "~~~~\n",
    "\n",
    "We will regenerate the model using the optimal parameters for the Boosted Decision Tree and fit on all of the given labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T14:26:09.238415Z",
     "start_time": "2017-07-11T14:24:45.248190Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator = PositiveIntegerGradientBoostingRegressor(n_estimators=1000, \n",
    "                                                 max_depth=model.best_params_['max_depth']) \n",
    "X_train = data.drop(['count', 'casual', 'registered'], axis=1).values\n",
    "y_train = data['count'].values\n",
    "estimator.fit(X_train, \n",
    "              y_train)\n",
    "\n",
    "testData = pandas.read_csv('test.csv')\n",
    "predictions = pandas.DataFrame(testData['datetime'])\n",
    "testData = coerceData(testData)\n",
    "predictions['count'] = estimator.predict(testData).astype('int')\n",
    "\n",
    "predictions.to_csv('submission.csv', \n",
    "                   sep=',', \n",
    "                   index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
